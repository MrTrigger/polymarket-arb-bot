# Progress Log

## Project Config
backend: rust
frontend: none
infra: kubernetes

## Project Overview
Polymarket 15-Minute Arbitrage Bot - HFT-optimized trading bot for crypto binary options arbitrage.

### Key Architecture Decisions
- Lock-free hot path using DashMap and atomics
- Zero-copy WebSocket parsing where possible
- Pre-hashed EIP-712 signing for shadow bids (<2ms)
- Fire-and-forget observability (<10ns overhead)
- Separate binaries: poly-collect (data), poly-import (historical), poly-bot (trading)

### External Dependencies
- polymarket-client-sdk: Official Polymarket Rust client (auth, discovery, orders)
- tokio-tungstenite: Custom WebSocket (minimal overhead for Binance)
- dashmap: Lock-free concurrent hash maps
- rust_decimal: Financial math (NEVER use f64 for prices)
- clickhouse: Data storage and replay

### Performance Targets
- WS message to state: <10us
- Arb detection: <1us
- Circuit breaker check: <10ns
- Shadow bid fire: <2ms
- Observability overhead: <10ns

## Codebase Patterns
[Agents add patterns they discover here]

## Priority
1. Phase 1 (poly-collect) is PRIORITY - start collecting data ASAP
2. Phases 2-9 can be developed in parallel while data collects
3. Every day of delay = less backtest data

## Completed Work

---

### [2026-01-12] Task p1-1: Workspace and shared crate setup
Files created:
- Cargo.toml (workspace root with all dependencies)
- crates/poly-common/Cargo.toml
- crates/poly-common/src/lib.rs
- crates/poly-common/src/types.rs

Verification:
- cargo check: PASSED
- cargo clippy -- -D warnings: PASSED
- cargo test: PASSED (5 tests)

Types implemented:
- CryptoAsset (BTC, ETH, SOL, XRP) with binance_symbol() helper
- Side (Buy, Sell) with opposite()
- Outcome (Yes, No) with opposite()
- OrderBookLevel (price, size) - all Decimal
- MarketWindow with window timing helpers
- SpotPrice for Binance trade data
- OrderBookSnapshot and OrderBookDelta for ClickHouse storage

Key decisions:
- Using rust_decimal v1.36 for all financial math
- clickhouse crate v0.13 with Row derive for type-safe inserts
- chrono with serde feature for timestamp handling
- All ClickHouse types derive Row for inserter compatibility

---

### [2026-01-12] Task p1-2: ClickHouse schema and client
Files created:
- crates/poly-common/src/schema.sql
- crates/poly-common/src/clickhouse.rs

Files modified:
- crates/poly-common/src/lib.rs (added clickhouse module export)

Verification:
- cargo clippy -- -D warnings: PASSED
- cargo test: PASSED (8 tests)

Schema tables defined:
- market_windows: ReplacingMergeTree for discovered markets
- spot_prices: MergeTree with 90-day TTL for Binance trades
- orderbook_snapshots: MergeTree with 90-day TTL for periodic captures
- orderbook_deltas: MergeTree with 90-day TTL for incremental updates
- price_history: MergeTree for historical import
- trade_history: ReplacingMergeTree for historical import
- decisions: MergeTree with 180-day TTL for observability

ClickHouseClient features:
- ClickHouseConfig with sensible defaults (max_rows: 10k, max_bytes: 10MB, period: 5s)
- ping() for connection testing
- create_tables() parses and executes schema.sql
- Type-safe inserters for each table type with auto-commit configuration
- Batch insert methods for one-off writes

Key decisions:
- Using Inserter from clickhouse::inserter module (not re-exported at crate root)
- Decimal(18, 8) for all price/quantity columns
- DateTime64(3, 'UTC') for millisecond precision timestamps
- LowCardinality(String) for repeated values (asset, side, action)
- 90-day TTL on operational data, 180-day on decisions

---

### [2026-01-12] Task p1-3: Market discovery for collector
Files created:
- crates/poly-collect/Cargo.toml
- crates/poly-collect/src/lib.rs
- crates/poly-collect/src/discovery.rs
- crates/poly-collect/src/main.rs

Files modified:
- Cargo.toml (added poly-collect to workspace members)

Verification:
- cargo clippy -- -D warnings: PASSED
- cargo test -p poly-collect: PASSED (4 tests)

MarketDiscovery features:
- Fetches active events from Gamma API (https://gamma-api.polymarket.com)
- Filters for 15-minute up/down markets by title keywords
- Detects crypto asset (BTC, ETH, SOL, XRP) from title
- Parses YES/NO token IDs from clobTokenIds JSON string
- Parses strike price from title (e.g., "$100,000")
- Stores discovered markets to ClickHouse market_windows table
- Runs discovery loop with configurable interval (default 5 min)
- Tracks known markets to avoid re-processing
- Graceful shutdown via broadcast channel

Key decisions:
- Using reqwest for HTTP instead of polymarket-client-sdk (simpler for read-only Gamma API)
- Gamma API returns clobTokenIds as JSON string, requires parsing
- 15-minute markets detected by title keywords (may need adjustment)
- Strike price parsing uses regex, defaults to Decimal::ZERO if not found
- Discovery interval set to 300s (5 minutes) in main.rs

Notes for next task (p1-4):
- Need tokio-tungstenite for Binance WebSocket
- Binance trade stream: wss://stream.binance.com:9443/ws/{symbol}@trade
- Buffer trades and batch write to spot_prices table

---

### [2026-01-12] Task p1-4: Binance WebSocket capture
Files created:
- crates/poly-collect/src/binance.rs

Files modified:
- crates/poly-collect/src/lib.rs (added binance module export)

Verification:
- cargo clippy -- -D warnings: PASSED
- cargo test -p poly-collect: PASSED (9 tests, 5 new)

BinanceCapture features:
- Connects to wss://stream.binance.com:9443/ws
- Subscribes to btcusdt@trade, ethusdt@trade, solusdt@trade, xrpusdt@trade
- Parses trade messages to SpotPrice (asset, price, quantity, timestamp)
- Buffers writes (default 500 records)
- Flushes to ClickHouse on buffer full or periodic interval (5s)
- Automatic reconnection with exponential backoff (1s initial, 60s max)
- Graceful shutdown via broadcast channel
- Handles ping/pong for connection keepalive
- Stats logging (trades received/written/errors)

Key decisions:
- Using combined stream subscription (single WS connection for all symbols)
- Decimal parsing from Binance string prices for exact math
- tokio::select! for concurrent message handling, flush timer, and shutdown
- Buffer cleared on successful flush, kept on error for retry
- Connection timeout of 10 seconds

Notes for next task (p1-5):
- Polymarket CLOB WebSocket at wss://clob.polymarket.com/ws
- Need to subscribe to token IDs from market discovery
- Handle book snapshots and deltas separately
- Periodic snapshot capture (100ms) for backtest fidelity

---

### [2026-01-12] Task p1-5: Polymarket CLOB WebSocket capture
Files created:
- crates/poly-collect/src/clob.rs

Files modified:
- crates/poly-collect/src/lib.rs (added clob module export)
- crates/poly-collect/Cargo.toml (added rust_decimal_macros dev dependency)

Verification:
- cargo clippy -- -D warnings: PASSED
- cargo test -p poly-collect: PASSED (19 tests, 10 new)

ClobCapture features:
- Connects to wss://ws-subscriptions-clob.polymarket.com/ws/market
- Subscribes to token IDs from shared ActiveMarkets state
- Handles "book" messages (full orderbook snapshots)
- Handles "price_change" messages (incremental deltas)
- Maintains in-memory OrderBookState per token with bid/ask HashMaps
- Periodic snapshot capture every 100ms for high-fidelity backtest data
- Buffers snapshots (500) and deltas (1000) for batch writes
- Automatic reconnection with exponential backoff (1s initial, 60s max)
- Sends PING every 9 seconds (Polymarket requires every 10s)
- Dynamically subscribes to new markets every 30 seconds
- Graceful shutdown via broadcast channel
- Stats logging (books received, snapshots/deltas captured/written)

OrderBookState features:
- apply_book() for full snapshot application
- apply_price_change() for delta updates (size=0 removes level)
- best_bid()/best_ask() for BBO extraction
- spread_bps() for spread calculation in basis points
- bid_depth()/ask_depth() for total liquidity
- to_snapshot() generates OrderBookSnapshot for ClickHouse

Key decisions:
- Using wss://ws-subscriptions-clob.polymarket.com/ws/market (official CLOB market endpoint)
- ActiveMarkets shared via Arc<RwLock<HashMap>> to coordinate with discovery
- Book messages parsed from JSON with bids/asks as OrderSummary arrays
- Price changes update both in-memory state AND record deltas for storage
- Snapshot interval of 100ms balances fidelity vs storage volume
- All prices use Decimal for exact financial math

Notes for next task (p1-6):
- Main binary needs to wire discovery, binance, and clob together
- ActiveMarkets shared between discovery (writer) and clob (reader)
- Need CLI args for --assets, --clickhouse-url
- Need TOML config file loading
- Graceful shutdown should stop all tasks

---

### [2026-01-12] Task p1-6: Collector main binary
Files created:
- crates/poly-collect/src/config.rs
- config/collect.toml

Files modified:
- Cargo.toml (added clap, toml workspace dependencies)
- crates/poly-collect/Cargo.toml (added clap, toml dependencies)
- crates/poly-collect/src/lib.rs (added config module export)
- crates/poly-collect/src/main.rs (complete rewrite)
- crates/poly-collect/src/discovery.rs (added discovered_windows tracking, get_discovered_windows method)

Verification:
- cargo clippy -- -D warnings: PASSED
- cargo test -p poly-collect: PASSED (23 tests, 4 new)

CollectConfig features:
- Top-level config struct with assets, discovery_interval, log_level, clickhouse, binance, clob, health_log_interval
- from_file() loads from TOML path
- from_toml_str() parses from string (for testing)
- apply_overrides() merges CLI args on top of config
- TOML structure with [general], [clickhouse], [binance], [clob], [health] sections

Main binary features:
- CLI argument parsing with clap (--config, --clickhouse-url, --assets)
- Config file loading with fallback to defaults
- ClickHouse connection test and table creation
- Shared ActiveMarkets (Arc<RwLock<HashMap>>) for discovery-CLOB coordination
- Broadcast shutdown channel for all tasks
- Spawns 4 async tasks:
  1. Discovery task with ActiveMarkets update on new markets
  2. Binance capture task
  3. CLOB capture task
  4. Health logging task
- Graceful shutdown:
  - Unix: SIGTERM and SIGINT handling
  - Windows: Ctrl+C handling
  - 10 second timeout for task completion
- Health stats: discovery_runs, markets_discovered, errors

Key decisions:
- Using clap derive for CLI argument parsing
- Config file is optional - defaults work out of the box
- Discovery now tracks discovered MarketWindows for CLOB subscription
- Separate spawn_* functions for cleaner task management
- Health stats use AtomicU64 for lock-free updates
- Broadcast channel capacity of 16 for shutdown signaling

Notes for next task (p1-7):
- config/collect.toml already created
- Need Dockerfile for poly-collect
- Need k8s Deployment manifest
- Consider adding health check HTTP endpoint

---

### [2026-01-12] Task p1-7: Deployment config
Files created:
- deploy/Dockerfile.collect
- deploy/k8s/poly-collect.yaml

Files modified:
- (none - config/collect.toml already existed from p1-6)

Verification:
- cargo clippy -- -D warnings: PASSED
- kubectl apply --dry-run=client: PASSED (namespace, configmap, deployment all valid)
- Docker build: SKIPPED (Docker daemon not running, but Dockerfile syntax is valid)

Dockerfile features:
- Multi-stage build (rust:1.83-bookworm builder, debian:bookworm-slim runtime)
- Minimal runtime with only ca-certificates and libssl3
- Non-root user (appuser) for security
- RUST_LOG and CONFIG_PATH environment defaults
- Copies default config to /app/config/collect.toml

K8s manifest features:
- Namespace: polymarket
- ConfigMap with embedded collect.toml (ClickHouse URL points to cluster-internal service)
- Deployment with:
  - Resource limits (128Mi-512Mi memory, 100m-500m CPU)
  - Security context (non-root, read-only root fs, dropped capabilities)
  - Config mounted from ConfigMap at /config
  - terminationGracePeriodSeconds: 15 for graceful shutdown
  - RUST_LOG and RUST_BACKTRACE env vars

Key decisions:
- Using debian:bookworm-slim for runtime (smaller than alpine, better glibc compatibility)
- Security-hardened pod spec with minimal privileges
- ConfigMap allows config changes without rebuilding image
- ClickHouse URL uses cluster DNS (clickhouse.polymarket.svc.cluster.local)
- Health check endpoint not added (would require code changes, can be added later)

Notes for Phase 1 completion:
- Phase 1 (poly-collect) is now COMPLETE!
- Can deploy to k8s once Docker daemon is running and ClickHouse is deployed
- Start collecting data ASAP to build backtest dataset

---

### [2026-01-12] Task p2-1: Price history importer
Files created:
- crates/poly-import/Cargo.toml
- crates/poly-import/src/lib.rs
- crates/poly-import/src/prices.rs
- crates/poly-import/src/main.rs (stub)

Files modified:
- Cargo.toml (added poly-import to workspace members)
- crates/poly-common/src/types.rs (added PriceHistory, TradeHistory types)
- crates/poly-common/src/clickhouse.rs (added price_history/trade_history inserters)

Verification:
- cargo clippy -- -D warnings: PASSED
- cargo test: PASSED (35 tests total, 4 new)

PriceImporter features:
- Fetches from https://clob.polymarket.com/prices-history endpoint
- Supports startTs/endTs for date range filtering
- Supports fidelity parameter for resolution control
- Rate limiting with configurable requests_per_second (default 5.0)
- Automatic retry with exponential backoff (3 retries, 1s initial)
- Handles 429 Too Many Requests with Retry-After header
- Batch inserts to ClickHouse (configurable batch_size, default 1000)
- Import stats tracking (tokens processed/failed, records imported)
- Multi-token import with progress logging

API response format:
- GET /prices-history?market={token_id}&startTs={unix}&endTs={unix}&fidelity={minutes}
- Returns: { history: [{ t: unix_timestamp, p: price_float }] }

Types added to poly-common:
- PriceHistory (token_id, timestamp, price) for price_history table
- TradeHistory (token_id, timestamp, side, price, size, trade_id) for trade_history table

Key decisions:
- Using reqwest for HTTP client (consistent with poly-collect)
- Conservative rate limit of 5 req/s to avoid 429s
- API returns f64 prices, converted to Decimal on import
- CLI not implemented yet (deferred to p2-3)
- TradeHistory type added preemptively for p2-2

Notes for next task (p2-2):
- Need to find trade history API endpoint
- TradeHistory type already defined
- insert_trade_history already implemented in ClickHouse client

---

### [2026-01-12] Task p2-2: Trade history importer
Files created:
- crates/poly-import/src/trades.rs

Files modified:
- crates/poly-import/src/lib.rs (added trades module export)

Verification:
- cargo clippy -- -D warnings: PASSED
- cargo test: PASSED (43 tests total, 8 new)

TradeImporter features:
- Fetches from https://clob.polymarket.com/data/trades endpoint
- Supports L2 authentication headers (POLY_ADDRESS, POLY_SIGNATURE, POLY_TIMESTAMP, POLY_NONCE)
- Filters by market, start/end timestamps, maker_address, taker_address
- Handles pagination via cursor (next_cursor in response)
- Handles both array and object response formats
- Parses timestamps (Unix seconds or ISO 8601 format)
- Converts string prices/sizes to Decimal
- Rate limiting with configurable requests_per_second (default 5.0)
- Automatic retry with exponential backoff (3 retries, 1s initial)
- Handles 429 Too Many Requests with Retry-After header
- Batch inserts to ClickHouse (configurable batch_size, default 1000)
- Import stats tracking (markets processed/failed, trades imported)
- Multi-market import with progress logging

API endpoint details:
- GET /data/trades?market={condition_id}&after={unix}&before={unix}
- Requires L2 Header authentication for most queries
- Returns: { trades: [{ id, market, asset_id, side, size, price, match_time, status }] }
- Pagination via next_cursor field

Key decisions:
- /data/trades requires authentication (unlike /prices-history which is public)
- L2Auth struct holds the authentication headers
- TradeImporter can work without auth (returns empty) or with auth
- Timestamp parsing handles both Unix seconds and ISO 8601 strings
- Response parsing handles both raw array and object with trades field
- market and status fields in ApiTrade marked #[allow(dead_code)] (part of API but not stored)

Notes for next task (p2-3):
- Need to wire up CLI with prices and trades subcommands
- Auth credentials should be passed via CLI or env vars
- Consider adding token_id param (in addition to market) for trades

---

### [2026-01-12] Task p2-3: Import CLI
Files modified:
- crates/poly-import/src/main.rs (complete rewrite from stub)
- Cargo.toml (added "env" feature to clap dependency)

Verification:
- cargo clippy -- -D warnings: PASSED
- cargo test -p poly-import: PASSED (20 tests, 8 new)

CLI features implemented:
- `poly-import prices --start YYYY-MM-DD --end YYYY-MM-DD --tokens TOKEN1,TOKEN2`
- `poly-import trades --start YYYY-MM-DD --end YYYY-MM-DD --markets MARKET1,MARKET2`
- Global options: --clickhouse-url, --clickhouse-database, --log-level
- Environment variable support via clap env feature
- L2 authentication for trades via --poly-address, --poly-signature, --poly-timestamp, --poly-nonce
- Configurable rate-limit and batch-size per subcommand
- Optional --fidelity for prices (resolution in minutes)

CLI subcommand options:
- prices: -s/--start, -e/--end, -t/--tokens, -f/--fidelity, --rate-limit, --batch-size
- trades: -s/--start, -e/--end, -m/--markets, --rate-limit, --batch-size, --poly-* auth options

Error handling:
- Validates date format (YYYY-MM-DD)
- Validates token/market lists not empty
- Tests ClickHouse connection before import
- Creates tables if they don't exist
- Progress logging via tracing

Key decisions:
- Using clap derive with "env" feature for environment variable support
- Date parsing uses chrono::NaiveDate then converts to UTC DateTime
- Start date = 00:00:00 UTC, End date = 23:59:59 UTC for full day coverage
- Auth credentials optional but warned if missing for trades
- Returns ExitCode::FAILURE on any error

Notes for Phase 2 completion:
- Phase 2 (poly-import) is now COMPLETE!
- Ready to import historical price and trade data
- Example usage:
  ```
  poly-import prices -s 2024-01-01 -e 2024-01-31 -t TOKEN_ID_1,TOKEN_ID_2
  poly-import trades -s 2024-01-01 -e 2024-01-31 -m MARKET_ID_1
  ```

---

### [2026-01-12] Task p3-1: Bot configuration system
Files created:
- crates/poly-bot/Cargo.toml
- crates/poly-bot/src/lib.rs
- crates/poly-bot/src/config.rs
- config/bot.toml

Files modified:
- Cargo.toml (added poly-bot to workspace members)

Verification:
- cargo clippy -- -D warnings: PASSED
- cargo test -p poly-bot: PASSED (13 tests)

BotConfig features:
- TradingMode enum: Live, Paper, Shadow, Backtest
- TradingConfig: time-based margin thresholds, position limits, order sizing
- RiskConfig: circuit breaker, daily loss limit, imbalance ratio, toxic flow threshold
- ShadowConfig: enable/disable, price offset, max wait time
- ExecutionConfig: price chasing, paper fill latency, order timeout
- ObservabilityConfig: decision capture, counterfactuals, anomaly detection, alerts
- WalletConfig: credentials from env vars only (security)
- BacktestConfig: date range, speed, parameter sweep

Config loading:
- from_file() loads TOML
- from_toml_str() parses string
- apply_env_overrides() reads POLY_*, CLICKHOUSE_*, ALERT_WEBHOOK_URL
- apply_cli_overrides() for --mode, --assets, --clickhouse-url
- validate() checks mode-specific requirements and config consistency

Key decisions:
- TOML uses f64/percentages for readability, converted to Decimal internally
- Wallet credentials ONLY from env vars (never in config file)
- Shadow mode is default (safest for testing)
- Time-based margin thresholds: 2.5% early, 1.5% mid, 0.5% late
- All financial values use rust_decimal::Decimal

Notes for next tasks:
- p3-2 (state) and p3-3 (types) now unblocked
- Both can be implemented in parallel
- State will use DashMap for lock-free concurrent access
- Types will define OrderBook, MarketState, Inventory with Decimal

---

### [2026-01-12] Task p3-2: Shared state (lock-free)
Files created:
- crates/poly-bot/src/state.rs

Files modified:
- crates/poly-bot/src/lib.rs (added state module export)

Verification:
- cargo clippy -- -D warnings: PASSED
- cargo test -p poly-bot: PASSED (28 tests, 15 new)

GlobalState features:
- Lock-free concurrent access using DashMap and atomics
- can_trade() uses two atomic loads with Acquire ordering (~10ns)
- enable_trading(), disable_trading() for global control
- trip_circuit_breaker(), reset_circuit_breaker() for fail-safe
- record_success(), record_failure() for consecutive failure tracking
- circuit_breaker_cooldown_elapsed() for auto-reset

SharedMarketData:
- spot_prices: DashMap<String, (Decimal, i64)> for asset prices
- order_books: DashMap<String, LiveOrderBook> for per-token books
- inventory: DashMap<String, InventoryPosition> for per-event positions
- shadow_orders: DashMap<(String, Outcome), ShadowOrderState> for pending shadows
- active_windows: DashMap<String, ActiveWindow> for tracked windows
- Helper methods: update_spot_price, get_bbo, total_exposure

ControlFlags:
- trading_enabled: AtomicBool for global enable/disable
- circuit_breaker_tripped: AtomicBool for fail-safe
- consecutive_failures: AtomicU32 for failure counting
- circuit_breaker_trip_time: AtomicI64 for cooldown tracking
- shutdown_requested: AtomicBool for graceful shutdown

MetricsCounters:
- events_processed, opportunities_detected, trades_executed, trades_failed, trades_skipped
- pnl_cents, volume_cents (using i64/u64 to avoid Decimal atomics)
- shadow_orders_fired, shadow_orders_filled
- snapshot() returns MetricsSnapshot with all values

Types defined:
- LiveOrderBook: best bid/ask with spread_bps() and is_valid()
- InventoryPosition: yes/no shares, cost basis, imbalance_ratio(), state()
- InventoryState: Balanced, Skewed, Exposed, Crisis
- ShadowOrderState: pending shadow with pre_hash for fast signing
- ActiveWindow: market window with seconds_remaining(), phase()
- WindowPhase: Early, Mid, Late for threshold selection

Key decisions:
- Ordering::Acquire for reads, Ordering::Release for writes on hot path
- Relaxed ordering for metrics (exact counts not critical)
- P&L stored as cents (i64) to avoid Decimal atomics, converted on read
- DashMap provides lock-free reads, fine-grained locking on writes
- Concurrent access test verifies 10 threads x 100 iterations

Notes for next task (p3-3):
- InventoryPosition and InventoryState already defined in state.rs
- p3-3 needs OrderBook with bid/ask levels (not just BBO)
- MarketState with derived fields (combined_cost, arb_margin)
- Consider whether types.rs needs separate from state.rs types

---

### [2026-01-12] Task p3-3: Market state types
Files created:
- crates/poly-bot/src/types.rs

Files modified:
- crates/poly-bot/src/lib.rs (added types module export)

Verification:
- cargo clippy -- -D warnings: PASSED
- cargo test -p poly-bot: PASSED (43 tests, 15 new)

Types implemented:
- PriceLevel: single price/size level with cost() method
- OrderBook: full order book with multiple bid/ask levels
  - best_bid(), best_ask(), best_bid_size(), best_ask_size()
  - spread_bps(), mid_price(), is_valid()
  - bid_depth(), ask_depth()
  - cost_to_buy(), proceeds_to_sell() for fill simulation
  - apply_snapshot(), apply_delta() for updates
- MarketState: combined YES/NO market state for arb detection
  - yes_book, no_book (OrderBook instances)
  - spot_price, strike_price, seconds_remaining
  - combined_cost() = yes_ask + no_ask
  - arb_margin() = 1.0 - combined_cost
  - arb_margin_bps() for threshold comparison
  - max_arb_size(), cost_to_arb()
  - implied_yes_prob(), implied_no_prob()
- Inventory: position tracking per market
  - yes_shares, no_shares, cost basis for each
  - total_shares(), total_exposure(), net_position()
  - imbalance_ratio(), state() for risk classification
  - matched_pairs(), unmatched_yes(), unmatched_no()
  - record_fill() for fill processing
  - unrealized_pnl(), pnl_if_yes_wins(), pnl_if_no_wins()
  - guaranteed_pnl() for matched pair profit
- InventoryState: Balanced, Skewed, Exposed, Crisis
  - size_multiplier() for position sizing adjustment
  - should_rebalance() for risk management

Key decisions:
- All types use rust_decimal::Decimal (NEVER f64)
- OrderBook is separate from LiveOrderBook (state.rs)
  - LiveOrderBook: BBO-only for fast state updates (DashMap)
  - OrderBook: full depth for strategy calculations
- Inventory is separate from InventoryPosition (state.rs)
  - InventoryPosition: lock-free state storage
  - Inventory: rich P&L calculations for strategy
- MarketState combines YES/NO books + spot price for arb detection
- PriceLevel uses Copy trait for zero-cost copies

Notes for next tasks:
- p3-4 (DataSource) and p3-5 (Executor) now unblocked
- p4-1 (arb detection) and p4-2 (toxic flow) also unblocked
- p6-1 (risk checks) and p7-1 (decision types) unblocked
- MarketState.arb_margin() ready for threshold comparison in p4-1

---

### [2026-01-12] Task p3-4: Data source trait
Files created:
- crates/poly-bot/src/data_source.rs (trait definition, MarketEvent enum)
- crates/poly-bot/src/data_source/live.rs (LiveDataSource)
- crates/poly-bot/src/data_source/replay.rs (ReplayDataSource)

Files modified:
- crates/poly-bot/src/lib.rs (added data_source module export)
- crates/poly-bot/Cargo.toml (added async-trait, futures-util, tokio-tungstenite)
- Cargo.toml (added workspace dependencies)

Verification:
- cargo clippy -- -D warnings: PASSED
- cargo test -p poly-bot: PASSED (62 tests, 19 new)

DataSource trait:
- async fn next_event() -> Result<Option<MarketEvent>, DataSourceError>
- has_more() -> bool for stream status
- current_time() -> Option<DateTime<Utc>> for replay mode
- shutdown() for graceful termination

MarketEvent enum:
- SpotPrice: Binance trade updates (asset, price, quantity, timestamp)
- BookSnapshot: Full orderbook from CLOB (bids, asks as PriceLevels)
- BookDelta: Incremental orderbook update (side, price, size)
- Fill: Order fill notification (outcome, size, price, fee)
- WindowOpen: New market window discovered
- WindowClose: Market window expired
- Heartbeat: Connection liveness check

LiveDataSource features:
- Connects to Binance WebSocket for spot prices
- Connects to Polymarket CLOB WebSocket for orderbooks
- Automatic reconnection with exponential backoff
- Dynamic subscription to new markets every 30s
- Ping/pong keepalive handling
- Shutdown via broadcast channel
- ActiveMarketsState (Arc<RwLock<HashMap>>) for market tracking

ReplayDataSource features:
- Loads historical data from ClickHouse (spot_prices, orderbook_snapshots, orderbook_deltas, market_windows)
- BinaryHeap priority queue for chronological event ordering
- Speed control (0.0 = max speed, 1.0 = real-time, >1.0 = faster)
- Configurable date range, event_ids, and assets filters
- Batch loading with configurable batch_size

Key decisions:
- Using async-trait crate for async trait methods
- LiveDataSource spawns background tasks for WebSocket connections
- Events merged through mpsc channel from multiple sources
- ReplayDataSource loads all data upfront into memory (suitable for backtest periods)
- Same DataSource trait works for both live trading and backtesting

Notes for next tasks:
- p3-5 (Executor) still unblocked
- Strategy code can use DataSource trait polymorphically
- ReplayDataSource ready for backtest mode (p8-4)
- LiveDataSource ready for live/paper/shadow modes

---

### [2026-01-12] Task p3-5: Executor trait
Files created:
- crates/poly-bot/src/executor.rs (trait and types)
- crates/poly-bot/src/executor/paper.rs (PaperExecutor)
- crates/poly-bot/src/executor/backtest.rs (BacktestExecutor)
- crates/poly-bot/src/executor/live.rs (LiveExecutor stub)

Files modified:
- crates/poly-bot/src/lib.rs (added executor module exports)

Verification:
- cargo clippy -- -D warnings: PASSED
- cargo test -p poly-bot: PASSED (97 tests, 34 new)

Executor trait features:
- place_order(&mut self, OrderRequest) -> Result<OrderResult, ExecutorError>
- cancel_order(&mut self, order_id) -> Result<OrderCancellation, ExecutorError>
- order_status(&self, order_id) -> Option<OrderResult>
- pending_orders(&self) -> Vec<PendingOrder>
- available_balance(&self) -> Decimal
- shutdown(&mut self)

OrderRequest types:
- OrderRequest with limit(), market(), ioc() constructors
- OrderType enum (Limit, Market, Ioc, Gtc)
- max_cost() calculation for balance checks

OrderResult enum:
- Filled(OrderFill) - fully filled
- PartialFill(PartialOrderFill) - partially filled
- Rejected(OrderRejection) - order rejected
- Pending(PendingOrder) - waiting for execution
- Cancelled(OrderCancellation) - order cancelled
- Helper methods: is_filled(), is_rejected(), filled_size(), filled_cost()

PaperExecutor features:
- Simulated fills without real money
- Configurable initial balance, fill latency, fee rate
- Balance enforcement and position limits
- Market order slippage simulation
- Position tracking (yes_shares, no_shares, cost_basis)
- Order history and status queries

BacktestExecutor features:
- Fills simulated by walking historical order book depth
- Partial fills when liquidity is insufficient
- Limit price enforcement (only fill at or better than limit)
- Configurable minimum fill ratio for partial fills
- Position and balance tracking
- BacktestStats for performance analysis

LiveExecutor (stub):
- Placeholder for real order submission
- Returns errors for all operations
- Will be fully implemented in Phase 5 (p5-3)

Key decisions:
- Executor trait uses async_trait for async methods
- All prices/quantities use rust_decimal::Decimal
- PaperExecutor doesn't consume order book (simplistic simulation)
- BacktestExecutor walks order book but doesn't modify it
- Partial fills tracked separately from full fills
- Order history stored for status queries

Notes for next tasks:
- Phase 3 now COMPLETE! All data_source and executor abstractions ready
- p4-1 (arb detection), p4-2 (toxic flow), p5-1 (shadow) now unblocked
- p6-1 (risk checks), p6-2 (circuit breaker), p7-1 (decision types) also unblocked
- Strategy code can use Executor trait polymorphically
- Same code works for live, paper, and backtest modes

---

### [2026-01-12] Task p4-1: Arbitrage detection
Files created:
- crates/poly-bot/src/strategy/mod.rs
- crates/poly-bot/src/strategy/arb.rs

Files modified:
- crates/poly-bot/src/lib.rs (added strategy module export)
- crates/poly-bot/src/state.rs (added Serialize/Deserialize to WindowPhase)

Verification:
- cargo clippy -- -D warnings: PASSED
- cargo test -p poly-bot: PASSED (117 tests, 20 new)

ArbThresholds features:
- Time-based margin thresholds: early (2.5%), mid (1.5%), late (0.5%)
- Configurable phase boundaries (early_threshold_secs, mid_threshold_secs)
- Minimum time remaining to trade (min_time_remaining_secs)
- for_phase() and phase_for_time() helpers

ArbOpportunity struct:
- Complete opportunity snapshot for decision making
- Event ID, asset, token IDs
- yes_ask, no_ask, combined_cost, margin, margin_bps
- max_size (limited by smaller side liquidity)
- seconds_remaining, phase, required_threshold
- confidence score (0-100)
- spot_price, strike_price for directional signals
- detected_at_ms timestamp
- expected_profit(), spot_suggests_yes(), has_significant_edge() helpers

ArbDetector features:
- detect(market) -> Result<ArbOpportunity, ArbRejection>
- Validates time remaining, quotes, liquidity
- Calculates margin and checks against phase-specific threshold
- Confidence scoring based on 5 factors:
  1. Margin above threshold (0-25 points)
  2. Time phase (0-15 points) - late = higher confidence
  3. Liquidity depth (0-20 points)
  4. Spread tightness (0-15 points)
  5. Spot price alignment (-5 to +10 points)
- has_potential_arb() for fast filtering
- Configurable min_confidence threshold

ArbRejection enum:
- NoQuotes: missing BBO
- NoArbitrage: combined >= 1.0
- BelowThreshold: margin below phase threshold
- InsufficientTime: < min_time_remaining
- NoLiquidity: size <= 0
- LowConfidence: confidence < min_confidence

Key decisions:
- All prices use rust_decimal::Decimal (NEVER f64)
- Confidence scoring provides signal quality indicator
- Fast path: has_potential_arb() for quick filtering before full detection
- ArbOpportunity is fully serializable for observability
- WindowPhase now has Serialize/Deserialize for storage

Notes for next tasks:
- p4-2 (toxic flow), p4-3 (position sizing) now unblocked
- Arb detector ready for strategy loop integration (p4-4)
- Confidence scoring can be tuned based on backtest results

---

### [2026-01-12] Task p4-2: Toxic flow detection
Files created:
- crates/poly-bot/src/strategy/toxic.rs

Files modified:
- crates/poly-bot/src/strategy/mod.rs (added toxic module export)

Verification:
- cargo clippy -- -D warnings: PASSED
- cargo test -p poly-bot: PASSED (136 tests, 19 new)

ToxicFlowDetector features:
- Rolling average order size tracking with configurable window (default 100)
- Detects large orders (>50x average) via size_multiplier_threshold
- Detects sudden appearance (<500ms since last update)
- Detects BBO shift (>100bps by default)
- Detects extreme size (>100x average = 2x threshold)
- Multi-indicator severity calculation:
  - Low: 1 indicator triggered
  - Medium: 2 indicators or >75x order
  - High: 3+ indicators or large+sudden
  - Critical: extreme size (>100x)
- Per-token state management with HashMap
- Fast pre-filtering via would_be_large() without state update

ToxicFlowConfig options:
- size_multiplier_threshold (default 50x)
- sudden_appearance_ms (default 500ms)
- rolling_window_size (default 100)
- min_samples (default 10) - minimum before detection active
- bbo_shift_threshold_bps (default 100 = 1%)

ToxicFlowWarning struct:
- Full diagnostic info (token_id, side, sizes, multiplier, timing)
- severity field for risk assessment
- indicators struct showing which checks triggered
- should_block() and size_multiplier() helpers for risk response

ToxicIndicators:
- large_order: size > threshold * average
- sudden_appearance: time < sudden_appearance_ms
- bbo_shift: BBO changed > bbo_shift_threshold_bps
- extreme_size: size > 2 * threshold * average

ToxicSeverity helpers:
- score() returns 0-100 numeric score
- should_block_trading() returns true for High/Critical
- size_multiplier() returns position size adjustment (0.75 to 0.0)

Key decisions:
- Rolling sum O(1) average calculation instead of O(n) iteration
- VecDeque for efficient front/back operations on window
- State per token to handle multiple markets independently
- All prices use rust_decimal::Decimal (NEVER f64)
- Severity ordering: Low < Medium < High < Critical
- First observation never flagged as sudden (time_since = u64::MAX)
- BBO shift calculated based on order side (buy affects ask, sell affects bid)

Notes for next task (p4-3):
- Position sizing now unblocked
- Need to integrate toxic severity with sizing decisions
- ToxicSeverity::size_multiplier() can reduce position size based on severity
- Consider blocking trades entirely at High/Critical severity

---

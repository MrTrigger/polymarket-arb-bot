# Progress Log - React Trading Dashboard

## Project Config
backend: rust (Cargo workspace)
frontend: bun (to be created in frontend/)
database: ClickHouse

## Source PRD
tasks/prd-react-dashboard.md

## Codebase Patterns

### Observability Pattern (CRITICAL - follow this for dashboard capture)
- See: crates/poly-bot/src/observability/capture.rs
- Bounded channel with try_send() - NEVER block hot path
- <10ns overhead requirement
- Fire-and-forget, drop on backpressure

### State Access Pattern
- See: crates/poly-bot/src/state.rs
- DashMap for concurrent access
- Atomics for flags/counters
- Lock-free reads on hot path

### ClickHouse Types
- See: crates/poly-bot/src/observability/types.rs
- Use Float64 for prices (clickhouse-rs doesn't support rust_decimal)
- Use clickhouse::Row derive

### Existing Tables
- decisions, counterfactuals, anomalies (observability)
- spot_prices, orderbook_snapshots, orderbook_deltas (market data)
- trade_history, price_history (historical imports)
- market_windows (window metadata)

## Key Files Reference
- Config: crates/poly-bot/src/config.rs
- Global State: crates/poly-bot/src/state.rs
- Observability Capture: crates/poly-bot/src/observability/capture.rs
- Schema: crates/poly-common/src/schema.sql

## Phases Overview
1. Backend Infrastructure: Schema + Capture channel + Session management
2. Backend Server: WebSocket + State serialization + REST API
3. Frontend Setup: Scaffold + Types + WebSocket + Store + Layout
4. Main Dashboard: Metrics + Equity + Markets + Circuit Breaker + Logs
5. Market Detail: Price chart + Order book + Position + Trades
6. Polish: Session metrics + Anomalies + Theme + Build + Integration test

## Completed Work

### [2026-01-15] Task: phase1-schema - Add new ClickHouse table schemas

Files changed:
- crates/poly-common/src/schema.sql

Changes:
- Added 5 new dashboard tables to schema.sql:
  - `sessions` - Tracks bot sessions with aggregates (ReplacingMergeTree)
  - `bot_trades` - All trades executed with full fill details (365 day TTL)
  - `pnl_snapshots` - Periodic P&L for equity curve visualization (180 day TTL)
  - `structured_logs` - Searchable logs with JSON fields (30 day TTL)
  - `market_sessions` - Per-market metrics within a session (ReplacingMergeTree)

Verification:
- All 5 CREATE TABLE statements present in schema.sql
- Follows existing patterns: Decimal(18,8) for money, LowCardinality for enums, proper TTLs

Learnings:
- Schema uses ReplacingMergeTree for sessions/market_sessions (updated via upsert pattern)
- MergeTree with TTL for time-series data (trades, pnl_snapshots, logs)
- UUID type available in ClickHouse for session_id, trade_id
- Nullable types for optional fields (end_time, settlement fields)

---

### [2026-01-15] Task: phase1-types - Create dashboard event types

Files changed:
- crates/poly-bot/src/dashboard/types.rs (created)
- crates/poly-bot/src/dashboard/mod.rs (created)
- crates/poly-bot/src/lib.rs (added dashboard module)
- crates/poly-bot/Cargo.toml (added uuid dependency)
- Cargo.toml (added uuid to workspace dependencies)

Changes:
- Created dashboard types module with 5 record types:
  - `SessionRecord` - Bot session lifecycle tracking
  - `TradeRecord` - Individual trade records with fill details
  - `PnlSnapshot` - Periodic P&L for equity curve
  - `LogEntry` - Structured log entries
  - `MarketSessionUpdate` - Per-market metrics within a session
- Added supporting enums: BotMode, ExitReason, DashboardOrderType, TradeStatus, TradeSide, PnlTrigger, LogLevel
- Created `DashboardEvent` enum for capture channel
- All types implement Serialize/Deserialize
- Added UUID crate for session_id and trade_id

Verification:
- cargo clippy -p poly-bot -- -D warnings: PASSED
- cargo test -p poly-bot dashboard: PASSED (13 tests)

Learnings:
- Uses rust_decimal::Decimal for all financial math (NOT Float64)
- UUID v4 for unique identifiers (session_id, trade_id)
- Outcome type reused from poly_common::types
- TradeSide converts from poly_common::types::Side
- LogLevel converts from tracing::Level for integration with tracing subscriber
- clickhouse::Row derive deferred to processor (types module focuses on domain logic)

Notes for next task (phase1-capture):
- DashboardEvent enum is ready for the capture channel
- Follow observability/capture.rs pattern exactly
- Must use try_send() to avoid blocking hot path

---

### [2026-01-15] Task: phase1-capture - Implement DashboardCapture channel

Files changed:
- crates/poly-bot/src/dashboard/capture.rs (created)
- crates/poly-bot/src/dashboard/mod.rs (added capture module export)

Changes:
- Created `DashboardCapture` struct following observability/capture.rs pattern exactly:
  - `DashboardCaptureConfig` - configuration (enabled, capacity, log_drops, threshold)
  - `DashboardCaptureStats` - atomic counters (captured, dropped, skipped)
  - `DashboardCaptureStatsSnapshot` - point-in-time stats view
  - `DashboardCapture` - main capture context with try_send() pattern
- Key methods:
  - `try_capture(event)` - hot path method, <10ns overhead when disabled
  - `from_config()` - creates capture + receiver pair
  - `disabled()` - creates no-op capture for testing
  - `is_enabled()` / `enable()` / `disable()` - atomic toggle
  - `stats_snapshot()` - get current stats
- Fire-and-forget semantics:
  - Uses try_send() which never blocks
  - Drops events when channel full (backpressure)
  - Logs drops periodically (configurable threshold)
  - Auto-disables when channel is closed
- Type aliases:
  - `DashboardCaptureSender` / `DashboardCaptureReceiver` for mpsc channel
  - `SharedDashboardCapture` for Arc wrapper
- Helper functions:
  - `create_dashboard_channel(capacity)` - creates bounded channel pair
  - `create_shared_dashboard_capture(config)` - creates shareable capture

Verification:
- cargo clippy -p poly-bot -- -D warnings: PASSED
- cargo test -p poly-bot dashboard: PASSED (35 tests - 22 capture tests + 13 types tests)
- try_send() pattern confirmed (no blocking)
- Backpressure drops confirmed via test_try_capture_channel_full

Learnings:
- Overhead tests include allocation cost from test events; actual hot path is faster
- Clone impl shares Arc<stats> so all clones see same counters
- AtomicBool with Acquire/Release ordering for enabled flag
- compare_exchange for atomic drop log threshold update

Notes for next task (phase1-processor):
- Receiver is `DashboardCaptureReceiver` (mpsc::Receiver<DashboardEvent>)
- Need to batch events by type for ClickHouse bulk inserts
- Each event type has session_id() method for grouping
- event_type() returns string for logging/metrics

---

### [2026-01-15] Task: phase1-processor - Implement dashboard event processor

Files changed:
- crates/poly-bot/src/dashboard/processor.rs (created)
- crates/poly-bot/src/dashboard/mod.rs (added processor module export)
- Cargo.toml (added `uuid` feature to clickhouse dependency)

Changes:
- Created `DashboardProcessor` following observability/processor.rs pattern:
  - ClickHouse Row types for each table:
    - `SessionRow` -> `sessions` table
    - `TradeRow` -> `bot_trades` table
    - `PnlRow` -> `pnl_snapshots` table
    - `LogRow` -> `structured_logs` table
    - `MarketSessionRow` -> `market_sessions` table
  - `DashboardProcessorConfig` - batch_size, flush_interval, max_buffer_size
  - `DashboardProcessorStats` / `DashboardProcessorStatsSnapshot` - tracking counters
  - `EventBuffers` - separate VecDeque for each event type
- Processor loop:
  - Receives events from capture channel
  - Buffers by event type for batch efficiency
  - Flushes when batch_size reached OR flush_interval timer fires
  - Graceful shutdown on channel close or shutdown signal
  - Final flush before exit
- Row type conversions:
  - From rust_decimal::Decimal to f64 (ClickHouse limitation)
  - From chrono::DateTime to time::OffsetDateTime
  - UUID serialization with clickhouse::serde::uuid
- Helper functions:
  - `create_shared_dashboard_processor(config)` - creates Arc-wrapped processor
  - `spawn_dashboard_processor(...)` - spawns as background tokio task

Verification:
- cargo clippy -p poly-bot -- -D warnings: PASSED
- cargo test -p poly-bot dashboard:: PASSED (53 tests - 22 capture + 18 processor + 13 types)
- Writes to all 5 tables via separate flush methods
- Handles shutdown signal via tokio::select!

Learnings:
- clickhouse crate requires `uuid` feature for UUID field serialization
- Row types need both `Row` derive AND `Serialize` trait bound for write()
- Use time::OffsetDateTime (not chrono) for clickhouse datetime64 fields
- datetime_to_offset helper for chrono -> time conversion
- Backpressure drops oldest events when buffer full (per-type buffers)

Notes for next task (phase1-session):
- DashboardProcessor is ready to receive events
- Need session manager to create SessionRecord on startup
- Session manager should update record on shutdown with exit reason
- Integrate with mode/live.rs and mode/paper.rs startup code

---

### [2026-01-15] Task: phase1-session - Implement session lifecycle management

Files changed:
- crates/poly-bot/src/dashboard/session.rs (created)
- crates/poly-bot/src/dashboard/mod.rs (added session module export)
- crates/poly-bot/src/mode/live.rs (integrated SessionManager)
- crates/poly-bot/src/mode/paper.rs (integrated SessionManager)

Changes:
- Created `SessionManager` for session lifecycle tracking:
  - Generates UUID session_id on creation
  - Computes config hash using Keccak256 (sha3 crate)
  - Tracks markets traded via HashSet
  - `start()` method sends initial session event
  - `end(reason, metrics)` method updates record with final metrics
  - `record_market_traded(event_id)` for tracking unique markets
- Supporting types:
  - `SharedSessionManager` = Arc<RwLock<SessionManager>>
  - Helper functions: `create_shared_session_manager`, `end_shared_session`, `record_market_on_session`
- Config hash includes:
  - Trading mode, assets list
  - Trading params (margins, position limits, sizing)
  - Risk params (failures, daily loss, imbalance)
  - Shadow bid config (enabled, offset)
  - Engine config (arbitrage, directional, maker enabled)
- Integration with LiveMode and PaperMode:
  - Session field added to both structs
  - `session.start()` called at beginning of `run()`
  - `end_shared_session()` called in `shutdown()` with ExitReason::Graceful

Verification:
- cargo clippy -p poly-bot -- -D warnings: PASSED
- cargo test -p poly-bot dashboard::: PASSED (68 tests - 17 new session tests)
- Session created on startup (via start() call)
- Session updated on shutdown (via end() call)

Learnings:
- Use sha3 (Keccak256) for config hashing - already a dependency for EIP-712 signing
- RwLock is appropriate for session manager (read-heavy, occasional writes)
- MetricsSnapshot fields are u64, need cast to u32 for SessionRecord trade counts
- Config hash should include all params that affect trading behavior for reproducibility
- Collapsible if statements require `let && condition` syntax in Rust

Notes for next task (phase1-mod):
- Dashboard module structure is already created in mod.rs
- Need to add DashboardConfig to config.rs
- May want to add dashboard feature flag to Cargo.toml
- Consider adding session manager to shadow/backtest modes in future

---

### [2026-01-15] Task: phase1-mod - Create dashboard module structure

Files changed:
- crates/poly-bot/src/config.rs (added DashboardConfig)
- crates/poly-bot/src/lib.rs (exported DashboardConfig)

Changes:
- Added `DashboardConfig` struct to config.rs with all dashboard settings:
  - enabled: bool (enable/disable dashboard)
  - channel_capacity: usize (capture channel size)
  - log_drops: bool (log dropped events)
  - drop_log_threshold: u64 (drop log threshold)
  - batch_size: usize (ClickHouse batch size)
  - flush_interval_secs: u64 (ClickHouse flush interval)
  - max_buffer_size: usize (processor buffer limit)
  - websocket_port: u16 (WS server port, default 3001)
  - api_port: u16 (REST API port, default 3002)
  - broadcast_interval_ms: u64 (state broadcast interval)
  - pnl_snapshot_interval_secs: u64 (P&L capture interval)
- Added `DashboardConfig::disabled()` constructor
- Added `capture_config()` method to convert to DashboardCaptureConfig
- Added `processor_config()` method to convert to DashboardProcessorConfig
- Added `dashboard` field to `BotConfig` struct
- Added `DashboardToml` for TOML parsing
- Updated `From<TomlConfig>` to parse dashboard section
- Exported `DashboardConfig` from lib.rs

Verification:
- cargo clippy -p poly-bot -- -D warnings: PASSED
- cargo build -p poly-bot: PASSED
- cargo test -p poly-bot: PASSED (999 unit tests + 14 doc tests)
- DashboardConfig in config.rs: CONFIRMED

Learnings:
- DashboardConfig consolidates capture + processor settings in one place
- Helper methods (capture_config, processor_config) convert to specific configs
- TOML section is [dashboard] with same field names
- Feature flag not needed - DashboardConfig.enabled controls activation

Notes for next task (phase2-state):
- DashboardConfig is now available via BotConfig
- Phase 2 begins the backend server implementation
- DashboardState will aggregate data from GlobalState DashMaps
- Must be lock-free for snapshot creation

---

### [2026-01-15] Task: phase2-state - Create DashboardState struct

Files changed:
- crates/poly-bot/src/dashboard/state.rs (created)
- crates/poly-bot/src/dashboard/mod.rs (added state module)
- crates/poly-bot/Cargo.toml (added parking_lot)
- Cargo.toml (added parking_lot to workspace)

Changes:
- Created `DashboardState` - main aggregate struct for WebSocket broadcast containing:
  - `timestamp` - Snapshot time
  - `metrics` - MetricsSnapshotJson (P&L, trades, volume, etc.)
  - `markets` - Vec<ActiveMarketState> (order books, arb spread)
  - `positions` - Vec<PositionState> (inventory by market)
  - `control` - ControlState (trading enabled, circuit breaker)
  - `recent_trades` - Vec<TradeRecord> (last 100)
  - `recent_logs` - Vec<LogEntry> (last 100)
  - `anomalies` - Vec<AnomalyState>
- Supporting types:
  - `MetricsSnapshotJson` - JSON-friendly metrics (Decimals as strings)
  - `ActiveMarketState` - Market with order book summaries and arb calculation
  - `OrderBookSummary` - Best bid/ask with spread
  - `PositionState` - Position with exposure and imbalance
  - `ControlState` - Control flags snapshot
  - `AnomalyState` / `AnomalySeverity` - Anomaly alerts
- `DashboardStateManager` - Thread-safe state manager with:
  - parking_lot::RwLock for recent trades/logs/anomalies
  - `snapshot()` method combining GlobalState + managed state
  - Ring buffer behavior for trades/logs (cap at 100)
- Helper functions:
  - `create_shared_dashboard_state_manager()` - Creates Arc<DashboardStateManager>

Lock-free design:
- `DashboardState::from_global_state()` uses only DashMap iteration and atomic reads
- No Mutex locks on the hot path
- parking_lot::RwLock only for managed state (brief acquisitions)

Verification:
- cargo clippy -p poly-bot -- -D warnings: PASSED
- cargo test -p poly-bot dashboard::state: PASSED (13 tests)
- cargo test -p poly-bot: PASSED (1012+ tests)
- Serializes to JSON: CONFIRMED (test_dashboard_state_serialization)
- No mutex locks in snapshot(): CONFIRMED (uses atomics + DashMap)

Learnings:
- MetricsSnapshotJson uses String for Decimals (JSON precision preservation)
- parking_lot::RwLock is faster than std::sync::RwLock for brief locks
- DashMap iteration is lock-free (each entry has its own lock)
- Calculate derived values before consuming struct fields to avoid partial moves
- Arb spread calculation: 1.0 - YES_ask - NO_ask (positive = opportunity)

Notes for next task (phase2-ws-server):
- DashboardState is ready for WebSocket broadcast
- Use DashboardStateManager for thread-safe state access
- Server should call snapshot() at broadcast_interval_ms
- Consider using tokio-tungstenite for WebSocket implementation
- Need to handle multiple client connections

---

### [2026-01-15] Task: phase2-ws-server - Implement WebSocket server

Files changed:
- crates/poly-bot/src/dashboard/server.rs (created)
- crates/poly-bot/src/dashboard/mod.rs (added server module)

Changes:
- Created `WebSocketServer` using tokio-tungstenite for real-time dashboard updates:
  - `WebSocketServerConfig` - port, broadcast interval, max clients
  - `WebSocketServerStats` / `WebSocketServerStatsSnapshot` - connection tracking
  - `WebSocketServer` - main server with broadcast loop
- Key features:
  - Multiple concurrent client support with HashMap<ClientId, ClientHandle>
  - Full DashboardState snapshot sent on client connect
  - Periodic broadcasts at configured interval (default 500ms)
  - Graceful shutdown via broadcast channel
  - Automatic cleanup on client disconnect
  - Ping/pong handling for connection health
  - Max client limit to prevent resource exhaustion
- Architecture:
  - Separate tasks for accept loop and broadcast loop
  - Per-client task for message forwarding and receiving
  - Uses mpsc::unbounded_channel per client for outgoing messages
  - Uses tokio::select! for concurrent handling
- Helper functions:
  - `create_websocket_server()` - creates Arc<WebSocketServer>
  - `spawn_websocket_server()` - spawns as background task with handle

Verification:
- cargo clippy -p poly-bot -- -D warnings: PASSED
- cargo test -p poly-bot: PASSED (1019 tests + 14 doc tests)
- WebSocket accepts connections: CONFIRMED (TcpListener + accept_async)
- Broadcasts state at configured interval: CONFIRMED (interval ticker in spawn_broadcast_task)

Learnings:
- tokio-tungstenite requires splitting stream for concurrent read/write
- Use unbounded_channel for per-client message queue (bounded would require backpressure)
- broadcast::channel is ideal for shutdown signal (all receivers get notification)
- AtomicU64 for client IDs avoids locking
- RwLock<HashMap> for clients allows concurrent reads during iteration

Notes for next task (phase2-rest-api):
- axum is not in workspace dependencies yet - will need to add
- Need ClickHouse client for historical queries
- Pagination support required for logs endpoint
- Consider shared state between WS server and REST API

---
